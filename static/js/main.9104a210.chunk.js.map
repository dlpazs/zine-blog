{"version":3,"sources":["components/cnn/cnn.zine.js","components/limitations/Limitations.js","components/layout/NavBar.js","components/topics/Topics.js","components/home/Home.js","components/sgd/SGD.js","components/batch_norm/BatchNorm.js","App.js","serviceWorker.js","index.js"],"names":["CNN","className","style","margin","backgroundColor","padding","borderRadius","src","width","height","Limitations","href","NavBar","class","type","data-toggle","data-target","aria-controls","aria-expanded","aria-label","id","to","Topics","match","Home","SGD","BatchNorm","App","exact","path","component","Boolean","window","location","hostname","ReactDOM","render","document","getElementById","navigator","serviceWorker","ready","then","registration","unregister"],"mappings":"mQA4FeA,EA1FH,kBACA,yBAAKC,UAAU,aACX,yBAAKA,UAAU,MACfC,MAAO,CACHC,OAAO,QAGP,yBAAKF,UAAU,OACf,mFACA,yBACAC,MAAO,CACHE,gBAAgB,UAChBC,QAAQ,OACRF,OAAO,OACPG,aAAa,QALjB,sjEAoCJ,6BAAS,6BACT,yEAMA,yBAAKC,IAAI,sCACTL,MAAO,CACHM,MAAM,MACNC,OAAO,SAGX,sDACA,4wBAUA,0CACA,+3BAWA,yBAAKF,IAAI,wEACTL,MAAO,CACHM,MAAM,aCwCXE,EA3HK,kBAClB,6BACE,8DACA,2BACA,4BACA,uBAAGC,KAAK,mFAAR,4CAFA,krJAsEJ,yBAAKJ,IAAI,wEAtEL,48GCmBWK,EArBA,kBACX,yBAAKC,MAAM,iDACP,uBAAGA,MAAM,eAAeF,KAAK,cAA7B,aACA,4BAAQE,MAAM,iBAAiBC,KAAK,SAASC,cAAY,WAAWC,cAAY,aAAaC,gBAAc,YAAYC,gBAAc,QAAQC,aAAW,qBACpJ,0BAAMN,MAAM,yBAGhB,yBAAKA,MAAM,2BAA2BO,GAAG,aACrC,wBAAIP,MAAM,cACV,wBAAIA,MAAM,mBACN,uBAAGA,MAAM,WAAWF,KAAK,cAAzB,QAA2C,0BAAME,MAAM,WAAZ,eAE/C,wBAAIA,MAAM,YACN,kBAAC,IAAD,CAAMA,MAAM,WAAWQ,GAAG,qBAA1B,eCiFDC,EA9FA,SAAC,GAAD,EAAGC,MAAH,OACb,yBACArB,MAAO,CACLC,OAAO,QAKP,sCAIA,yBAAKU,MAAM,MAAKX,MAAO,CACPC,OAAO,QAErB,yBAAKU,MAAM,YACT,yBAAKA,MAAM,QACT,yBAAKA,MAAM,aACT,wBAAIA,MAAM,cAAV,mCACA,uBAAGA,MAAM,aAAT,+KAGA,kBAAC,IAAD,CAAMQ,GAAG,QAAQR,MAAM,mBAAvB,WAIN,yBAAKA,MAAM,YACT,yBAAKA,MAAM,QACT,yBAAKA,MAAM,aACT,wBAAIA,MAAM,cAAV,eACA,uBAAGA,MAAM,aAAT,kJAGA,kBAAC,IAAD,CAAMQ,GAAG,eAAeR,MAAM,mBAA9B,WAIN,yBAAKA,MAAM,YACT,yBAAKA,MAAM,QACT,yBAAKA,MAAM,aACT,wBAAIA,MAAM,cAAV,OACA,uBAAGA,MAAM,aAAT,kJAGA,kBAAC,IAAD,CAAMQ,GAAG,OAAOR,MAAM,mBAAtB,YAOR,yBAAKA,MAAM,MAAKX,MAAO,CACPC,OAAO,QAErB,yBAAKU,MAAM,YACT,yBAAKA,MAAM,QACT,yBAAKA,MAAM,aACT,wBAAIA,MAAM,cAAV,cACA,uBAAGA,MAAM,aAAT,+KAGA,kBAAC,IAAD,CAAMQ,GAAG,cAAcR,MAAM,mBAA7B,WAIN,yBAAKA,MAAM,YACT,yBAAKA,MAAM,QACT,yBAAKA,MAAM,aACT,wBAAIA,MAAM,cAAV,eACA,uBAAGA,MAAM,aAAT,kJAGA,kBAAC,IAAD,CAAMQ,GAAG,eAAeR,MAAM,mBAA9B,WAIN,yBAAKA,MAAM,YACT,yBAAKA,MAAM,QACT,yBAAKA,MAAM,aACT,wBAAIA,MAAM,cAAV,OACA,uBAAGA,MAAM,aAAT,kJAGA,kBAAC,IAAD,CAAMQ,GAAG,OAAOR,MAAM,mBAAtB,cCxEGW,EAZF,kBACX,6BACA,oCACA,6UCgBaC,EAnBH,kBACR,yBACAvB,MAAO,CACHC,OAAO,QAEP,2DACA,qGACA,uLAII,6BACA,yBAAKI,IAAI,6DACT,6BACA,yBAAKA,IAAI,0ECgCNmB,EA9CG,kBACd,6BACI,0CAEA,0IAGA,iDACA,kKAKA,6BACA,yBAAKnB,IAAI,iEACT,6BAPA,4vECkCOoB,MAtBf,WACE,OACE,yBAAK1B,UAAU,aACb,kBAAC,IAAD,KACA,kBAAC,EAAD,MACA,yBAAKA,UAAU,OAEb,6BACE,kBAAC,IAAD,CAAO2B,OAAK,EAACC,KAAK,aAAaC,UAAWN,IAC1C,kBAAC,IAAD,CAAOK,KAAK,oBAAoBC,UAAWR,IAC3C,kBAAC,IAAD,CAAOO,KAAK,QAAQC,UAAW9B,IAC/B,kBAAC,IAAD,CAAO6B,KAAK,eAAeC,UAAWpB,IACtC,kBAAC,IAAD,CAAOmB,KAAK,OAAOC,UAAWL,IAC9B,kBAAC,IAAD,CAAOI,KAAK,cAAcC,UAAWJ,SCvB3BK,QACW,cAA7BC,OAAOC,SAASC,UAEe,UAA7BF,OAAOC,SAASC,UAEhBF,OAAOC,SAASC,SAASX,MACvB,2DCZNY,IAASC,OAAO,kBAAC,EAAD,MAASC,SAASC,eAAe,SD2H3C,kBAAmBC,WACrBA,UAAUC,cAAcC,MAAMC,MAAK,SAAAC,GACjCA,EAAaC,kB","file":"static/js/main.9104a210.chunk.js","sourcesContent":["import React, { Component } from \"react\";\r\n\r\nconst CNN = () => (\r\n            <div className=\"container\">\r\n                <div className=\"row\"\r\n                style={{\r\n                    margin:\"5vh\"\r\n                }}\r\n                >\r\n                    <div className=\"col\">\r\n                    <h1>Everybody loves ... convolutions (Work in progress)</h1>\r\n                    <div\r\n                    style={{\r\n                        backgroundColor:\"#f2f2f2\",\r\n                        padding:\"10px\",\r\n                        margin:\"10px\",\r\n                        borderRadius:\"5px\"\r\n                    }}\r\n                    >\r\n                        In 3D, the following mental image may prove useful. Imagine two sheets of colored paper: \r\n                one red and one blue. Put one on top of the other. Now crumple them together into a small \r\n                ball. That crumpled paper ball is your input data, and each sheet of paper is a class of \r\n                data in a classification problem. What a neural network (or any other machine-learning model) \r\n                is meant to do is figure out a transformation of the paper ball that would uncrumple it, so \r\n                as to make the two classes cleanly separable again. With deep learning, this would be \r\n                implemented as a series of simple transformations of the 3D space, such as those you could \r\n                apply on the paper ball with your fingers, one movement at a time. \r\n\r\n                Uncrumpling paper balls is what machine learning is about: finding neat representations \r\n                for complex, highly folded data manifolds. At this point, you should have a pretty good \r\n                intuition as to why deep learning excels at this: it takes the approach of incrementally \r\n                decomposing a complicated geometric transformation into a long chain of elementary ones, \r\n                which is pretty much the strategy a human would follow to uncrumple a paper ball. \r\n                Each layer in a deep network applies a transformation that disentangles the data a \r\n                little - and a deep stack of layers makes tractable an extremely complicated \r\n                disentanglement process.\r\n\r\n                \r\n                \r\n                Conv layers look at spatially local patterns by applying the same geometric transformation to \r\n                different spatial locations (patches) in an input tensor. This results in a representation that \r\n                are translation invariant (does not matter where in the image the object occurs). Convnets consist \r\n                of stacks of convolution and max-pooling layers. The pooling layers let you spatially downsample the \r\n                data, which is required to keep feature maps to a reasonable size as the number of features grows, \r\n                and to allow subsequent convolution layers to see a greater spatial extent of the inputs. Convnets \r\n                are often ended with a `Flatten` operation or global pooling layer, turning spatial feature maps \r\n                into vectors, followed by `Dense` layers to achieve classification or regression.\r\n                <br></br><br></br>\r\n                <b>Deep Learning with Python page 44–5.</b>\r\n                    </div>\r\n                \r\n                \r\n                \r\n\r\n                <img src=\"https://i.stack.imgur.com/iY5n5.png\"\r\n                style={{\r\n                    width:\"50%\",\r\n                    height:\"30%\"\r\n                }}/>\r\n\r\n                <h2>What is a convolution?</h2> \r\n                <p>\r\n                It is a sliding window applied to a matrix, whether that be an image or feature map. At each element we multiply the \r\n                filter/kernel with the corresponding input pixel and then add them up. The same filter/kernel is slide across the input \r\n                which is called weight tying. Filters of the convolutions are learned, so the model learns which filter is best to apply \r\n                in each layer. An early layer of a convolution is likely, at best, to only detect very low level features such as edges. \r\n                This is because the filters are limited at earlier layers, whereas as we go deeper, the amount of output channels (which we set) \r\n                increases and later layers have several channels with which to predict collections of edges and orientations that make up a face or eye ball. \r\n                </p>\r\n                \r\n\r\n                <h2>Properties</h2> \r\n                <p>\r\n                Location Invariance and Compositionality. Say you want to spot a cat in an image. Because of this sliding window \r\n                approach you don't care where the cat occurs. The second aspect is (local) compositionality. Each filter composes \r\n                a local patch of lower-level features into higher-level representation. You build edges from pixels, shapes from edges, \r\n                eyes from circles and so on. You can derive more complex shapes and objects from lower level representations such as \r\n                edges, pixels, gradients etc and from several channels of these features.\r\n\r\n                Convolutions are translationally invariant because the filters slide over the image horizontally and vertically. \r\n                But they are not rotationally invariant because the filters don't rotate. Thus, the net seems to need several similar \r\n                filters in different orientations to detect objects and patterns that are differently oriented.\r\n                </p>\r\n                <img src=\"https://cdn-images-1.medium.com/max/1200/1*B41mvbzpZ7ythn5AlJWh-A.gif\" \r\n                style={{\r\n                    width:\"90%\"\r\n                }}/>\r\n                    </div>\r\n                </div>\r\n            </div>\r\n)\r\n\r\nexport default CNN\r\n\r\n","import React from 'react';\r\n\r\nconst Limitations = () => (\r\n  <div>\r\n    <h1>Limitations (Work in progress)</h1>\r\n    <p>\r\n    <h2>\r\n    <a href=\"http://faculty.neu.edu.cn/yury/AAI/Textbook/Deep%20Learning%20with%20Python.pdf\">\r\n        Heavily Inspired by this brilliant book</a>\r\n    </h2>\r\n\r\nDeep learning works by doing a series of geometric transformations on an input. And then, \r\ngiven some error signal, improves the geometric transformations iteratively to map some \r\ninput x to a correct output y. \r\n\r\n\"In deep learning, everything is a vector: everything is a point in a geometric space. \r\nModel inputs and targets are first vectorized: turned into an initial input vector space \r\nand target vector space. Each layer operates one simple geometric transformation on the \r\ndata that goes through it. The chain of layers forms one complex geometric trasnformation, \r\nbroken down into a series of simpler ones. This complex transformation attempts to map the \r\ninput space to the target space, one point at a time. This transformation is parameterized \r\nby weights of the layers, which are iteratively updated based on how well the model is \r\ncurrently performing. A key characteristic is that the geometric trasnformation must be \r\ndifferentiable, to be able to perform gradient descent. Thi means the geometric morphing \r\nfrom inputs to outputs must be smooth and continuous - a significant constraint.\"\r\n\r\n\"The entire process of applying this complex geometric transformation to the input data can be \r\nvisualized in 3D by imagining a person trying to uncrumple a paper ball: the crumpled paper ball \r\nis the manifold of the input data that the model starts with.\r\nEach movement operated by the person on the paper ball is similar to a simple geometric \r\ntransformation operated by one layer. The full uncrumpling gesture sequence is the complex \r\ntransformation of the entire model. Deep-learning models are mathematical machines for uncrumpling \r\ncomplicated manifolds of high-dimensional data.\r\n\r\nThat’s the magic of deep learning: turning meaning into vectors, into geometric spaces, and \r\nthen incrementally learning complex geometric transformations that map one space to another. \r\nAll you need are spaces of sufficiently high dimensionality in order to capture the full scope \r\nof the relationships found in the original data.\"\r\n\r\n\"The whole thing hinges on a single core idea: that meaning is derived from the pairwise \r\nrelationship between things (between words in a language, between pixels in an image) and \r\nthat these relationships can be captured by a distance function. If the brain works in \r\ngeometric spaces is a different question. Vector spaces are efficient to work with from a \r\ncomputational standpoint, but different data structures can be envisioned- like graphs. \r\nNeural networks initially emerged from using graphs (connectionism) but nowadays they have \r\nan incorrect meaning since they are neither neural nor networks. A more appropriate name is \r\nlayered representations learning or hierarchical representations learning, or deep differentiable \r\nmodels or chained geometric transforms.\"\r\n\r\n\"The space of applications is nearly infinite but many are completely out of reach for current \r\ndeep learning techniques. You cannot train a model to read a product description and generate \r\nthe appropriate codebase. Anything that requires reasoning, long-term planning, and algorithmic \r\ndata manipulation is out of reach for deep-learning models no matter how much data is given. \r\n\r\nThis is because a deep-learning model is just a chain of simple, continuous geometric \r\ntransformation mapping one vector space into another. All it can do is map one data manifold X \r\ninto another manifold Y, assuming the existence of a learnable continuous transform from X to Y.\"\r\n\r\n\"One real risk is overestimating/ anthropomorphizing deep-learning models and their abilities. \r\nA fundamental feature of humans is our theory of mind: our tendency to project intentions, beliefs, \r\nand knowledge on the things around us. Drawing a smiley face on a rock suddenly makes it happy-in \r\nour minds. Applied to deep learning, this means that, for instance, when we're able to train a \r\nmodel to generate captions to describe pictures and the captions it generates. Then we're \r\nsurprised when any slight departure from the sort of images present in the training data \r\ncauses the model to generate completely absurd captions. \r\n\r\nThis is highlighted by adversarial examples, which are samples ged to a deep-learning network \r\nthat are designed to trick the model into misclassifying them. It's possible to do gradient \r\nascent in input space to generate inputs that maximize the activation of some convnet filter-this \r\nis the basis of the filter-visualization technique. Similarly, through gradient ascent you can \r\nslightly modify an image to maximize the class prediction for a given class. By taking a \r\npicture of a panda and adding to it a gibbon gradient, we can get a neural network to classify \r\nthe panda as a gibbon. This evidences both the brittleness of these models and the deep \r\ndifference between their input-to-output mapping and our human perception.\"\r\n\r\n<img src=\"https://blog.keras.io/img/limitations-of-dl/adversarial_example.png\" />\r\n\"In short, deepl-learning models don't have any understanding of their input-not in the human \r\nsense. Our understanding of images, sounds etc is grounded in our sensimotor experience as humans. \r\nML models have no access to such experiences and thus can't understand their inputs in a human \r\nrelatable way. By annotating large numbers of training examples to feed to our models, we get \r\nthem to learn a geometric transform that maps data to human concepts on a specific set of examples, \r\nbut this mapping is a simplistic sketch of the original model in our minds-the one developed from \r\nour experience as embodied agents.\r\n\r\nNever fall into the trap of believing that neural networks understand the task they perform. \r\nThey were trained on a different, far narrower task than the one we wanted to teach them: that of \r\nmapping training inputs to training targets, point by point. Show them anything that deviates from \r\ntheir training data, and they will break.\"\r\n\r\n\"Humans are capable of far more than mapping immediate stimuli to immediate\r\nresponses, as a deep network, or maybe an insect, would. We maintain complex, abstract\r\nmodels of our current situation, of ourselves, and of other people, and can use these\r\nmodels to anticipate different possible futures and perform long-term planning. We\r\ncan merge together known concepts to represent something we’ve never experienced \r\nbefore-like picturing a horse wearing jeans, for instance. This ability to hypothecize, \r\nto expand our mental model beyond what we can experience directly-to perform abstraction \r\nand reasoning-is arguably the defining characterstic of human cognition. \r\nExtreme generalization: an ability to adapt to novel, never-before experienced \r\nsituations using little data or no new data. This stands in sharp contrast with deep nets, \r\nlocal generalization. The mapping from inputs to outputs performed by deep net quickly \r\nstops making sense if new inputs deviate from what was seen during training. Consider, \r\nfor instance, the problem of learning the appropriate launch parameters to get a rocket \r\nto land on the moon. If you used a deep net for this task and trained\r\nit using supervised learning or reinforcement learning, you’d have to feed it thousands\r\nor even millions of launch trials: you’d need to expose it to a dense sampling of the input\r\nspace, in order for it to learn a reliable mapping from input space to output space. In\r\ncontrast, as humans we can use our power of abstraction to come up with physical \r\nmodels—rocket science—and derive an exact solution that will land the rocket on the moon\r\nin one or a few trials. Similarly, if you developed a deep net controlling a human body,\r\nand you wanted it to learn to safely navigate a city without getting hit by cars, the net\r\nwould have to die many thousands of times in various situations until it could infer that\r\ncars are dangerous, and develop appropriate avoidance behaviors. Dropped into a new\r\ncity, the net would have to relearn most of what it knows. On the other hand, humans\r\nare able to learn safe behaviors without having to die even once—again, thanks to our\r\npower of abstract modeling of hypothetical situations.\"\r\n\r\n\"In short, despite our progress on machine perception, we’re still far from humanlevel AI. \r\nOur models can only perform local generalization, adapting to new situations that must be \r\nsimilar to past data, whereas human cognition is capable of extreme generalization, quickly \r\nadapting to radically novel situations and planning\r\nfor long-term future situations.\"\r\n</p>\r\n  </div>\r\n);\r\n\r\nexport default Limitations;","import React from 'react';\r\nimport {  Link } from 'react-router-dom'\r\n\r\nconst NavBar = () => (\r\n    <nav class=\"navbar navbar-expand-lg navbar-light bg-light\">\r\n        <a class=\"navbar-brand\" href=\"/zine-blog\">DL Zine's</a>\r\n        <button class=\"navbar-toggler\" type=\"button\" data-toggle=\"collapse\" data-target=\"#navbarNav\" aria-controls=\"navbarNav\" aria-expanded=\"false\" aria-label=\"Toggle navigation\">\r\n            <span class=\"navbar-toggler-icon\"></span>\r\n        </button>\r\n\r\n        <div class=\"collapse navbar-collapse\" id=\"navbarNav\">\r\n            <ul class=\"navbar-nav\">\r\n            <li class=\"nav-item active\">\r\n                <a class=\"nav-link\" href=\"/zine-blog\">Home <span class=\"sr-only\">(current)</span></a>\r\n            </li>\r\n            <li class=\"nav-item\">\r\n                <Link class=\"nav-link\" to=\"/zine-blog/topics\">Topics</Link>\r\n                \r\n            </li>\r\n            </ul>\r\n        </div>\r\n    </nav>\r\n);\r\n\r\nexport default NavBar;\r\n","import React from 'react';\r\nimport { Link } from 'react-router-dom';\r\n\r\nconst Topics = ({ match }) => (\r\n  <div\r\n  style={{\r\n    margin:\"5vh\"\r\n}}>\r\n\r\n\r\n\r\n    <h1>Topics</h1>\r\n\r\n\r\n\r\n    <div class=\"row\"style={{\r\n                    margin:\"5vh\"\r\n                }}>\r\n      <div class=\"col-sm-4\">\r\n        <div class=\"card\">\r\n          <div class=\"card-body\">\r\n            <h5 class=\"card-title\">Everybody loves Convolutions...</h5>\r\n            <p class=\"card-text\">The focus here is on convolutional neural networks,\r\n            the convolution operation and how it relates to neural nets, \r\n            seeing convolution as just matrix multiplication and more!</p>\r\n            <Link to=\"/cnns\" class=\"btn btn-primary\">Read</Link>\r\n          </div>\r\n        </div>\r\n      </div>\r\n      <div class=\"col-sm-4\">\r\n        <div class=\"card\">\r\n          <div class=\"card-body\">\r\n            <h5 class=\"card-title\">Limitations</h5>\r\n            <p class=\"card-text\">The aim of this post is to learn about the Limitations\r\n            of neural networks before you embark on some new project so you can avoid\r\n            wasting time.</p>\r\n            <Link to=\"/limitations\" class=\"btn btn-primary\">Read</Link>\r\n          </div>\r\n        </div>\r\n      </div>\r\n      <div class=\"col-sm-4\">\r\n        <div class=\"card\">\r\n          <div class=\"card-body\">\r\n            <h5 class=\"card-title\">SGD</h5>\r\n            <p class=\"card-text\">The aim of this post is to learn about the Limitations\r\n            of neural networks before you embark on some new project so you can avoid\r\n            wasting time.</p>\r\n            <Link to=\"/sgd\" class=\"btn btn-primary\">Read</Link>\r\n          </div>\r\n        </div>\r\n      </div>\r\n    </div>\r\n\r\n\r\n    <div class=\"row\"style={{\r\n                    margin:\"5vh\"\r\n                }}>\r\n      <div class=\"col-sm-4\">\r\n        <div class=\"card\">\r\n          <div class=\"card-body\">\r\n            <h5 class=\"card-title\">Batch Norm</h5>\r\n            <p class=\"card-text\">The focus here is on convolutional neural networks,\r\n            the convolution operation and how it relates to neural nets, \r\n            seeing convolution as just matrix multiplication and more!</p>\r\n            <Link to=\"/batch_norm\" class=\"btn btn-primary\">Read</Link>\r\n          </div>\r\n        </div>\r\n      </div>\r\n      <div class=\"col-sm-4\">\r\n        <div class=\"card\">\r\n          <div class=\"card-body\">\r\n            <h5 class=\"card-title\">Limitations</h5>\r\n            <p class=\"card-text\">The aim of this post is to learn about the Limitations\r\n            of neural networks before you embark on some new project so you can avoid\r\n            wasting time.</p>\r\n            <Link to=\"/limitations\" class=\"btn btn-primary\">Read</Link>\r\n          </div>\r\n        </div>\r\n      </div>\r\n      <div class=\"col-sm-4\">\r\n        <div class=\"card\">\r\n          <div class=\"card-body\">\r\n            <h5 class=\"card-title\">SGD</h5>\r\n            <p class=\"card-text\">The aim of this post is to learn about the Limitations\r\n            of neural networks before you embark on some new project so you can avoid\r\n            wasting time.</p>\r\n            <Link to=\"/sgd\" class=\"btn btn-primary\">Read</Link>\r\n          </div>\r\n        </div>\r\n      </div>\r\n    </div>\r\n\r\n\r\n\r\n  </div>\r\n);\r\n\r\nexport default Topics;","import React from 'react';\r\n\r\nconst Home = () => (\r\n  <div>\r\n  <h1>Home</h1>\r\n  <p>\r\n    This site is designed to produce helpful content for people trying to learn deep learning and\r\n    for me to formalize my understanding. I try and take work from brilliant educators and \r\n    practioners and condense and describe them in a simplistic way to enable new comers to learn\r\n    without being intimidated.\r\n  </p>\r\n</div>\r\n);\r\n\r\nexport default Home;\r\n","import React from \"react\"\r\n\r\nconst SGD = () => (\r\n    <div\r\n    style={{\r\n        margin:\"5vh\"\r\n    }}>\r\n        <h1>Stochastic Gradient Descent</h1>\r\n        <h2>How do you create a predictor function as a function of pixel values?</h2>\r\n        <p>\r\n            What does this mean? Well the broader question here is how does a simple series\r\n            of matrix multiplications result in a good prediction based on its input. \r\n\r\n            <br></br>\r\n            <img src=\"https://latex.codecogs.com/gif.latex?%24y%3Dmx&plus;b%24\"></img>\r\n            <br></br>\r\n            <img src=\"https://latex.codecogs.com/gif.latex?%24y%3Da_1x_1&plus;a_2*x_2%24\"></img>\r\n        </p>\r\n    </div>\r\n)\r\n\r\nexport default SGD","import React from \"react\"\r\n\r\nconst BatchNorm = () => (\r\n    <div>\r\n        <h1>Batch Norm</h1>\r\n\r\n        <h3>What is Batch Normalization? It accelerates training by reducing internal covariate shift. \r\n            ... Or does it?\r\n        </h3>\r\n        <h3>How does it work?</h3>\r\n        <p>\r\n        Batch norm removes the mean and and divides by the standard deviation of a \r\n        channel of activations. \r\n\r\n        Insert Channel Activation picture\r\n        <br></br>\r\n        <img src=\"https://miro.medium.com/max/810/1*Hiq-rLFGDpESpr8QNsJ1jg.png\"></img>\r\n        <br/>\r\n        \"How does batch normalization help optimization? Not by reducing internal covariate shift. \r\n        What it does do, is allow you to increase your learning rate. The standard training without \r\n        batch norm has a much more bumpier loss landscape but with batch norm there are less big bumps. \r\n        So there is less risk of divergence. It is simple, it takes a mini-batch and it’s activations. \r\n        Firstly, we find the mean of the activativations, then the variance. Then we normalize, \r\n        so element-wise activation values minus the mean divided by the standard deviation. The \r\n        really important bit is: we take those normalized activation values and we add a vector \r\n        of biases. Then we use something that’s like a bias but instead we multiply by it. We \r\n        have a gamma which we multiply by those normalized activations and add a bias beta. \r\n        These two parameters are learnable parameters. The value of our predictions \r\n        y_hat = f(w_1, w_2,...,w_n, X) is some function of our weights (there could be millions) \r\n        and our input. This is our neural net function. Our loss: L = Sum(y_hat-y)^2. We want to \r\n        predict outcomes between 1 and 5. Our activations and our final layer are between -1 and 1, \r\n        and they’re way off. The scale is off the mean is off. One thing we can do is try to come \r\n        up with new weights to cause the spread and mean to increase. But this is hard since all \r\n        these weights interact in specific ways. So that will take ages. But what if we amended \r\n        that neural net function: y_hat = f(w_1, w_2, …, w_n, X) * gamma + beta. These are two \r\n        more parameter vectors, so this is really easy. To increase the scale or change the mean \r\n        we have these two parameters and we have their gradient to increase the scale/mean. That \r\n        is what batch norm does. It makes it easier to shift the outputs up and down etc. \r\n        In practice, we don’t use a different mean and standard deviation for each mini-batch \r\n        since it would vary so greatly. So instead we take the exponentially weighted moving \r\n        average of the mean and standard deviation. They use the same technique as they did for \r\n        adam to calculate this. You can vary the amount of momentum in the batch norm layer. The \r\n        smaller the momentum the less the standard deviation and mean will vary less from mini-batch \r\n        to mini-batch and will have less of a regularising effect.\"\"\r\n        </p>\r\n    </div>\r\n)\r\n\r\nexport default BatchNorm","import React from 'react';\n// import logo from './logo.svg';\nimport './App.css';\nimport { Route, Link, BrowserRouter as Router } from 'react-router-dom'\nimport CNN from \"./components/cnn/cnn.zine\"\nimport Limitations from \"./components/limitations/Limitations\"\nimport NavBar from \"./components/layout/NavBar\"\nimport Topics from \"./components/topics/Topics\"\nimport Home from \"./components/home/Home\"\nimport SGD from \"./components/sgd/SGD\"\nimport BatchNorm from \"./components/batch_norm/BatchNorm\"\n\nconst styles = {\n  background: '#000',\n  width: '2px',\n  cursor: 'col-resize',\n  margin: '0 5px',\n  height: '100%',\n  backgroundColor: \"#ccfff5\",\n  color: \"black\"\n};\n\nfunction App() {\n  return (\n    <div className=\"container\">\n      <Router>\n      <NavBar/>\n      <div className=\"App\">\n          \n        <div>\n          <Route exact path=\"/zine-blog\" component={Home}/>\n          <Route path=\"/zine-blog/topics\" component={Topics}/>\n          <Route path=\"/cnns\" component={CNN} />\n          <Route path=\"/limitations\" component={Limitations} />\n          <Route path=\"/sgd\" component={SGD} />\n          <Route path=\"/batch_norm\" component={BatchNorm} />\n\n        </div>\n      </div>\n    </Router>\n    </div>\n  );\n}\n\nexport default App;\n","// This optional code is used to register a service worker.\n// register() is not called by default.\n\n// This lets the app load faster on subsequent visits in production, and gives\n// it offline capabilities. However, it also means that developers (and users)\n// will only see deployed updates on subsequent visits to a page, after all the\n// existing tabs open on the page have been closed, since previously cached\n// resources are updated in the background.\n\n// To learn more about the benefits of this model and instructions on how to\n// opt-in, read https://bit.ly/CRA-PWA\n\nconst isLocalhost = Boolean(\n  window.location.hostname === 'localhost' ||\n    // [::1] is the IPv6 localhost address.\n    window.location.hostname === '[::1]' ||\n    // 127.0.0.1/8 is considered localhost for IPv4.\n    window.location.hostname.match(\n      /^127(?:\\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/\n    )\n);\n\nexport function register(config) {\n  if (process.env.NODE_ENV === 'production' && 'serviceWorker' in navigator) {\n    // The URL constructor is available in all browsers that support SW.\n    const publicUrl = new URL(process.env.PUBLIC_URL, window.location.href);\n    if (publicUrl.origin !== window.location.origin) {\n      // Our service worker won't work if PUBLIC_URL is on a different origin\n      // from what our page is served on. This might happen if a CDN is used to\n      // serve assets; see https://github.com/facebook/create-react-app/issues/2374\n      return;\n    }\n\n    window.addEventListener('load', () => {\n      const swUrl = `${process.env.PUBLIC_URL}/service-worker.js`;\n\n      if (isLocalhost) {\n        // This is running on localhost. Let's check if a service worker still exists or not.\n        checkValidServiceWorker(swUrl, config);\n\n        // Add some additional logging to localhost, pointing developers to the\n        // service worker/PWA documentation.\n        navigator.serviceWorker.ready.then(() => {\n          console.log(\n            'This web app is being served cache-first by a service ' +\n              'worker. To learn more, visit https://bit.ly/CRA-PWA'\n          );\n        });\n      } else {\n        // Is not localhost. Just register service worker\n        registerValidSW(swUrl, config);\n      }\n    });\n  }\n}\n\nfunction registerValidSW(swUrl, config) {\n  navigator.serviceWorker\n    .register(swUrl)\n    .then(registration => {\n      registration.onupdatefound = () => {\n        const installingWorker = registration.installing;\n        if (installingWorker == null) {\n          return;\n        }\n        installingWorker.onstatechange = () => {\n          if (installingWorker.state === 'installed') {\n            if (navigator.serviceWorker.controller) {\n              // At this point, the updated precached content has been fetched,\n              // but the previous service worker will still serve the older\n              // content until all client tabs are closed.\n              console.log(\n                'New content is available and will be used when all ' +\n                  'tabs for this page are closed. See https://bit.ly/CRA-PWA.'\n              );\n\n              // Execute callback\n              if (config && config.onUpdate) {\n                config.onUpdate(registration);\n              }\n            } else {\n              // At this point, everything has been precached.\n              // It's the perfect time to display a\n              // \"Content is cached for offline use.\" message.\n              console.log('Content is cached for offline use.');\n\n              // Execute callback\n              if (config && config.onSuccess) {\n                config.onSuccess(registration);\n              }\n            }\n          }\n        };\n      };\n    })\n    .catch(error => {\n      console.error('Error during service worker registration:', error);\n    });\n}\n\nfunction checkValidServiceWorker(swUrl, config) {\n  // Check if the service worker can be found. If it can't reload the page.\n  fetch(swUrl)\n    .then(response => {\n      // Ensure service worker exists, and that we really are getting a JS file.\n      const contentType = response.headers.get('content-type');\n      if (\n        response.status === 404 ||\n        (contentType != null && contentType.indexOf('javascript') === -1)\n      ) {\n        // No service worker found. Probably a different app. Reload the page.\n        navigator.serviceWorker.ready.then(registration => {\n          registration.unregister().then(() => {\n            window.location.reload();\n          });\n        });\n      } else {\n        // Service worker found. Proceed as normal.\n        registerValidSW(swUrl, config);\n      }\n    })\n    .catch(() => {\n      console.log(\n        'No internet connection found. App is running in offline mode.'\n      );\n    });\n}\n\nexport function unregister() {\n  if ('serviceWorker' in navigator) {\n    navigator.serviceWorker.ready.then(registration => {\n      registration.unregister();\n    });\n  }\n}\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport * as serviceWorker from './serviceWorker';\n\nReactDOM.render(<App />, document.getElementById('root'));\n\n// If you want your app to work offline and load faster, you can change\n// unregister() to register() below. Note this comes with some pitfalls.\n// Learn more about service workers: https://bit.ly/CRA-PWA\nserviceWorker.unregister();\n"],"sourceRoot":""}